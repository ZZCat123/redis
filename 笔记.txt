数据结构和内部编码
String：raw、int、embstr
hash：hashtable、ziplist（压缩列表）
list：linkedlist、ziplist
set：hashtable、intset
zset：skiplist、ziplist

单线程为什么这么快：
1.纯内存
2.非阻塞IO
3.避免线程切换和竞态消耗

字符串类型String
场景：缓存、计数器、分布式锁等等
set key value：不管key是否存在，都设置，O(1)
setnx key value：key不存在才设置，O(1)
set key value xx：key存在才设置，O(1)
mget key1 key2 key3...：批量获取key，原子操作，O(n)
mset key1 value1 key2 value2 key3 value3...：批量设置key-value，O(n)
getset key newvlaue：set key newvlaue并返回旧的value，O(1)
append key value：将value追加到旧value， O(1)
strlen key：返回字符串的长度（注意中文），O(1)

哈希类型Hash（small redis，类似于MapMap的结构，本身是一个map结构，其中的value也是一个map）
hget key filed：获取hash key对应的filed的value，O(1)
hset key field value：设置hash key对应的field的value，O(1)
hdel key field：删除hash key对应field的value，O(1)
hexists key field：判断hash key是否有field，O(1)
hlen key：获取hash key field的数量，O(1)
hmget，hmset类似于String的mset和mget
hgetall key：返回hash key对应所有的field和value，O(n)
hvals key：返回hash key对应所有field的value，O(n)
hkeys key：返回hash key对应所有的field，O(n)

list类型
rpush key value1 value2 ... valueN：从列表右端插入值（1~N）个，O(1~N)
lpush key value1 value2 ... valueN：从列表左端插入值（1~N）个，O(1~N)
linsert key before|after value newValue：在list指定的值之前|后插入newValue，O(n)
lpop key：从列表左端弹出一个value，O(1)
rpop key：从列表右侧弹出一个value，O(1)
lrem key count value：根据count值，从列表中删除所有的value相等的项，
                     count>0，从左到右，删除最多count个与value相等的值
                     count<0，从右到左，删除最多Math.abs（count）个与value相等的值
                     count=0，删除所有的与value相等的值
ltrim key start end：按照索引范围修剪列表
lrange key start end：获取列表指定索引范围所有的value（包括end），O(n)
lindex key index：获取列表指定索引的value，O(n)
llen key：获取列表长度，O(1)
lset key index newValue：设置列表指定索引值为newValue，O(n)
blpop/brpop key timeout：lpop阻塞版本，timeout是阻塞超时时间，timeout=0表示永不阻塞，O(1)
命令组合：1.lpush + lpop = stack
        2.lpush + rpop = queue
        3.lpush + ltrim = capped collection固定大小的容器
        4.lpush + brpop = message queue

集合set
sadd key element：向集合key添加element（如果element已存在，则添加失败），O(1)
scard key：统计集合元素个数
sismember key element：元素element是否在集合key中
srandmember key count：从集合key中随机取出count个元素，但该元素不会被从集合删除
spop key：从集合key中随机弹出一个元素，弹出后集合就不存在该元素
smembers key：取出集合key中的所有元素
srem key element：将集合key中的element移除掉，O(1)
sdiff key1 key2：输出集合key1和key2的差集（key1 - key2）
sinter key1 key2：输出集合key1和key2的交集
sunion key1 key2：输出key1和key2的并集
sdiff|sinter|sunion store destkey：将差|交|并集存在集合destkey中
命令组合实战：sadd = tagging做标签
           spop/srandmember = random item 随机操作，例如抽奖
           sadd + sinter = social graph社交网络，共同好友

有序集合zset
特点：key ： value（score ： value），无重复元素，有序，value由score + element组成，score保证顺序
zadd key score element（可以是多对）：添加score和element，O(logN)
zrem key element（可以是多个）：删除元素
zscore key element：返回元素的分数
zincreby key increScore element：增加或减少元素的score，O(1)
zcard key：返回元素的个数，O(1)
zrank|zrevrank key element：返回element在集合中的升序|降序顺序
zrange|zrevrange key start end [withscores]：返回指定索引范围内的升序|降序元素[分值]，O(logn + m）
zrangebyscore|zrevrangebyscore key minscore maxscore [withscores]：返回指定范围内的升序|降序元素[分值]
zcount key minscore maxscore：返回有序集合内指定范围内的元素个数，O(logn + m）
zremrangebyrank key start end：删除指定排名内的升序元素，O(logn + m）
zremrangebyscore key minscore maxscore：删除指分数内的升序元素，O(logn + m）
实战：排行榜

慢查询
客户端与redis服务器交互的生命周期：1.客户端发送命令 2.命令排队 3.执行命令 4.服务器返回给客户端结果
慢查询发生在第3阶段
客户端超时不一定是因为慢查询，但慢查询是客户端超时的一个可能因素
慢查询的两个配置
1.slowlog-max-len  先进先出队列，固定长度，保存在内存内
2.slowlog-log-slower-than  慢查询阈值（单位：微秒，0.001毫秒）
                           slowlog-log-slower-than = 0 记录所有命令
                           slowlog-log-slower-than < 0 不记录任何命令
慢查询命令：
1.slowlog get [n] ：获取慢查询队列
2.slowlog len：获取慢查询队列长度
运维经验：
1.slowlog-max-len不要设置过大，默认10ms，通常设置为1ms
2.slowlog-log-slower-than不要设置过小，通常在1000左右
3.理解生命周期

流水线pipeline（打包发送一批命令去服务端执行，节省网络传输时间）
1次pipeline（n条命令） = 1次网络时间 + n次命令时间
注意：1.redis的命令时间是微妙级别
     2.pipeline每次条数要控制（网络）
使用建议：
    1.注意每次pipeline携带的数据量
    2.pipeline每次只能作用在一个redis节点上

发布订阅
角色：发布者（publisher）、订阅者（subscriber）、频道（channel）
publish channel message ：发布消息，返回订阅者数量
subscribe [channel] ：订阅一个或多个频道
unsubscribe [channel] ：取消订阅一个或多个频道

位图bitmap
setbit key offset value ：给位图指定索引设置值
getbit key offset ：获取位图指定索引的值
bitcount key [start end] ：获取指定范围（start - end，单位为字节，如果不指定就是获取全部）位值为1的个数
bitop op destkey key [key...] ：做多个Bitmap的and（交集）、or（并集）、not（非）、xor（异或）操作，并将结果保存在destkey中
bitops key targetBit [start][end] ：计算位图指定范围（start到end，单位为字节，如果不指定就是获取全部）第一个偏移量对应的值等于targetBit的位置

HyperLoglog
基于HyperLoglog算法：极小空间完成独立数量统计
本质还是字符串
pfadd key element [element...] ：向hyperloglog添加元素
pfcount key [key...] ：计算hyperloglog的独立总数
pfmerge destkey sourcekey [sourcekey...] ：合并多个hyperloglog
使用经验：
    1.是否能容忍错误？错误率0.81%
    2.是否需要取出单挑数据？hyperloglog做不到

GEO
GEO(地理信息定位，Geographic information positioning)
存储经纬度，计算两地距离，范围计算等
geoadd key longitude latitude member [longitude latitude member...] ：增加地理位置信息
geopos key member [member...] ：获取地理位置信息
geodist key member1 member2 [unit] ：获取两个地理位置的距离，unit：m（米）、km（千米）、mi（英尺）、ft（尺）
相关说明：
    1.since3.2+
    2、数据类型是zset
    3.没有删除API，可用zset的删除操作进行删除：zrem key member

持久化RDB、AOF
redis所有数据保存在内存中，对数据的更新将异步地保存在磁盘上。
持久化方式：
    快照：1.MySQL Dump   2.Redis RDB
    写日志：1.MySQL Binlog   2.Hbase Hlog   3.Redis AOF

RDB
触发机制（三种）：save（同步）、bgsave（异步）、自动生成
save命令：文件策略：如存在老的RDB文件，新的替换老的，复杂度：O(n)
bgsave命令：异步创建子进程进行RDB操作，文件策略与save相同
自动生成RDB：在redis.conf文件中进行配置（内部是运行bgsave进行RDB的生成）
总结：1.RDB是Redis内存到硬盘的快照，用于持久化
     2.save命令通常会阻塞Redis
     3.bgsave不会阻塞Redis，但是会fork新进程
     4.save自动配置满足任意一个就会被执行（一般不使用自动策略）
     5.一些触发RDB的机制不容忽视（全量复制、debug reload、shutdown等）

AOF
RDB存在的问题：1.耗时、耗性能 2.不可控、丢失数据
AOF的三种策略：
    1.always：实时写入AOF文件，优点：不丢失数据   缺点：IO开销大，一般的SATA盘只有几百TPS
    2.everysec：每秒写一次AOF文件（配置默认值），优点：每秒一次fsync   缺点：丢失1s数据
    3.no：操作系统决定什么时候进行AOF操作，优点：不用管   缺点：不可控
AOF重写：1.AOF持久化是通过保存被执行的写命令来记录数据库状态的，所以AOF文件的大小随着时间的流逝一定会越来越大；
        影响包括但不限于：对于Redis服务器，计算机的存储压力；AOF还原出数据库状态的时间增加；
        2.为了解决AOF文件体积膨胀的问题，Redis提供了AOF重写功能：Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，
        新旧两个文件所保存的数据库状态是相同的，但是新的AOF文件不会包含任何浪费空间的冗余命令，
        通常体积会较旧AOF文件小很多。
AOF重写实现的两种方式：1.bgrewriteaof，fork子进程进行AOF重写
                   2.AOF重写配置，auto-aof-rewrite-min-size aof文件重写需要的尺寸
                                auto-aof-rewrite-percentage aof文件增长率

RDB个AOF的抉择
对比： 命令          RDB         AOF
      启动优先级     低          高（同时存在优先加载）
      体积          小          大
      恢复速度       快          慢
      数据安全性     丢数据       根据策略而定
      轻重          重          轻

Redis持久化在开发运维常见问题
fork操作：
    1.同步操作
    2.执行时间与内存量息息相关：内存越大，耗时越长（与机器类型有关）
    3.info：latest_fork_usec 上一次执行fork操作所耗微秒数，该数字如果较大会阻塞Redis
改善fork
    1.优先使用物理机或者高效支持fork操作的虚拟化技术
    2.控制Redis实例最大可用内存：maxmemory
    3.合理配置Linux内存分配策略：vm.overcommit_memory = 1
    4.降低fork频率：例如放宽AOF重写自动触发时机，不必要的全量复制
子进程开销和优化
    1.CPU：
        开销：RDB和AOF文件生成，属于CPU密集型
        优化：不做CPU绑定，不和CPU密集型一起部署
    2.内存：
        开销：fork内存开销，copy-on-write
        优化：系统方面可以进行优化
    3.硬盘
        开销：RDB和AOF文件写入，可以结合iostat，iotop分析
        优化：不要和高硬盘负载服务部署在一起：存储服务、消息队列等。
             no-appendfsync-on-rewrite = yes
             根据写入量决定磁盘类型：例如ssd
             单机多实例持久化文件目录可以考虑分盘

主从复制
一主一从、多主多从
主从复制的作用：数据副本、扩展读性能
总结：
    1.一个master可以有多个slave
    2.一个slave只能有一个master
    3.数据流是单向的，只能从master到slave
两种实现方式：1.slaveof命令      2.配置
全量复制开销：
    1.bgsave时间
    2.RDB文件网络传输时间
    3.从节点清空数据时间
    4.从节点加载RDB时间
    5.可能的AOF重写操作
部分复制：master保存一份缓冲buffer（类似于队列），slave重新连接的时候检测offset是否在队列中，
        若在，master会发送continue给slave，此时发生部分复制
        若不在，则会发生全量复制
故障处理：
    无故障转移
        slave宕机：将宕机掉的slave上的请求转移到其他的slave上
        master宕机：选取一个salve成为新的master对外提供服务
开发与运维中的问题：
    1.读写分离：读流量分摊到从节点
        可能遇到的问题：
            复制数据延迟
            读到过期的数据
            从节点故障
    2.配置不一致
        master和slave的maxmemory（slave的maxmemory小于master的maxmemory）不一致：丢失数据
        数据结构优化参数（例如hash-max-ziplist-entries）：内存不一致
    3.规避全量复制
        第一次全量复制
            出现情况：slave第一次去连接master，第一次不可避免
            解决方案：小主节点、低峰
        节点运行ID不匹配
            出现情况：主节点重启（运行ID变化）
            解决方案：故障转移，例如哨兵和集群
        复制积压缓冲区（默认1M）不足
            出现情况：网络中断，部分复制无法满足
            解决方案：增大缓冲区配置rel_backlog_size，网络增强
        避免复制风暴（master上挂载大量从节点，在master宕机后，会进行大量复制（生成rdb文件，大量传输））
            单主节点复制风暴
                出现情况：只有一个master节点，master节点重启，多从节点复制
                解决方案：更换复制拓扑
            单机器复制风暴
                出现情况：但台机器上放置多个master，机器宕机后，发生大量全量复制
                解决方案：主节点分散到多台机器上

Redis Sentinel
主从复制问题：1.手动故障转移 2.写能力和存储能力受限
三个定时任务
1.每10s每个sentinel对master和slave进行info
    发现slave节点
    确认主从关系
2.每2s每个sentinel通过master节点的channel交换信息（pub/sub）
    通过"_sentinel_:hello"频道交互
    交互对节点的"看法"和自身信息
3.每1s每个sentinel对其他sentinel和redis执行ping
    心跳检测，失败判定依据
主观下线和客观下线（判断是否下线master，即master是否有问题）
    主观下线：每个sentinel节点对redis节点失败的"偏见"
    客观下线：所有sentinel节点对redis节点失败"达成共识"（超过quorum统一）
            sentinel is-master-down-by-addr
领导者（sentinel）选举
    原因：只有一个sentinel节点完成故障转移
    选举：通过sentinel is-master-down-by-addr命令都希望成为领导者
        1.每个做主观下线的sentinel节点向其他sentinel节点发送的命令，要求将他设置为领导者
        2.收到命令的sentinel节点如果没有同意其他sentinel节点发送的命令，那么将同意该请求，否则拒绝
        3.如果该sentinel节点发现自己的票数已经超过sentinel集合半数且超过quorum，那么它将成为领导者
        4.如果此过程有多个sentinel节点成为了领导者，那么将等待一段时间重新进行选举
故障转移（sentinel领导者节点选举完成）
    1.从slave节点选出一个"合适的"节点作为新的master节点
    2.对上面的slave节点执行slaveof no one命令让其成为新的master节点
    3.向剩余的slave节点发送命令，让它们成为新的master节点的slave节点，复制规则和parallel-syncs参数有关
    4.更新原来的master节点配置为slave，并保持对其"关注"，当其恢复后命令它去复制新的master节点
选择"合适的"slave节点
    1.选择slave-priority（slave节点优先级）最高的节点，如果存在则返回，不存在则继续。
    2.选择复制偏移量最大的slave节点（复制的最完整），如果存在则返回，不存在则继续
    3.选择runId最小的slave节点
Redis Sentinel的常见开发运维问题
节点运维：主节点、从节点、sentinel节点
    1.机器下线：例如过保等情况
    2.机器性能不足：例如CPU、内存、硬盘、网络等
    3.节点自身故障：例如服务不稳定等
节点下线
    主节点下线:sentinel failover <mastername>手动下线主节点
    从节点：临时下线还是永久下线，例如是否做一些清理工作。但是要考虑读写分离的情况
    sentinel节点：同从节点
节点上线
    主节点：sentinel failover进行替换
    从节点：slaveof即可，sentinel节点可以感知
    sentinel节点：参考其他的sentinel节点启动即可
高可用读写分离（基于Redis Sentinel）
    从节点的作用：
        1.副本：高可用的基础
        2.扩展：读能力
    三个消息
        1.+switch-master：切换主节点（slave晋升为master）
        2.+convert-to-slave：切换从节点（原主节点降为从节点）
        3.+sdown：主观下线
总结：
    1.Redis Sentinel是Redis的高可用实现方案：故障发现、故障自动转移、配置中心、客户端通知
    2.Redis Sentinel从Redis2.8版本才开始正式生产可用，之前的版本生产不可用
    3.尽可能在不同的物理机器上部署Redis Sentinel所有节点
    4.Redis Sentinel的Sentinel节点个数应该大于等于3，且最好为奇数
    5.Redis Sentinel中的数据节点与普通数据节点没有区别
    6.客户端初始化时连接的是Sentinel节点集合，不再是具体的Redis节点，但是Sentinel只是配置中心，并不是代理
    7.Redis Sentinel通过三个定时任务实现了Sentinel节点对于主节点、从节点、其余Sentinel节点的监控
    8.Redis Sentinel在对节点做失败判定时分为主观下线和客观下线
    9.看懂Redis Sentinel故障转移日志对于Redis Sentinel以及问题排查非常有帮助
    10.Redis Sentinel实现读写分离高可用可以依赖Sentinel节点的消息通知，获取Redis节点数据的状态变化

Redis Cluster Redis集群
为什么需要集群：
    1.并发量（单机Redis -> 10万QPS），并发量超过单机极限，就需要集群
    2.数据量，数据量超过但台机器内存极限
    2.网络流量，网络流量超过但台机器网卡网速的极限
Redis 3.0及之后的版本开始支持Redis Cluster
数据分布
   |---------------------------------------------|
   | 分布方式 |       特点       |   典型产品        |
   |---------------------------------------------|
   | 哈希分布 |   数据分散度高    |  一致性哈希Memcache|
   |        |  键值分布与业务无关 |  Redis Cluster  |
   |        |  无法顺序访问      |  其他缓存产品      |
   |        |  支持批量操作      |                 |
   |---------------------------------------------|
   | 顺序分布 |   数据分散度易倾斜 |    BigTable      |
   |        |   键值业务相关     |   HBase         |
   |        |  可顺序访问        |                 |
   |        | 支持批量操作       |                 |
   |---------------------------------------------|
哈希分布：
    1.节点取余分区
        客户端分片：哈希 + 取余
        节点伸缩：数据节点关系变化，导致数据迁移
        迁移数量和添加节点数量有关：建议翻倍扩容（迁移率在50%）
    2.一致性哈希分区
        客户端分片：哈希 + 顺时针（优化取余）
        节点伸缩：只影响临近节点，但还是有数据迁移
        翻倍伸缩：保证最小迁移数据和负载均衡
    3.虚拟槽分区（Redis Cluster的分区方式）
        预设虚拟槽：每个槽映射一个数据子集，一般比节点数大
        良好的哈希函数：例如CRC16
        服务端管理节点、槽、数据：例如Redis Cluster
Redis Cluster架构
    1.配置节点
    2.节点之间meet
    3.给每个节点指派槽
    4.主从复制 redis-cli -p [slave port] cluster replicate [master port]
原生命令安装
    理解Redis Cluster架构
    生产环境不使用
官方工具安装
    高效、准确
    生产环境可以使用
其他安装
    可视化部署

集群伸缩
集群伸缩 = 槽和数据在节点之间移动
扩容集群
    准备新节点
        集群（Cluster）模式启动
        配置和其他节点统一
        启动后是孤儿节点
    加入集群（meet）
        执行meet操作
        作用：实现扩容、作为从节点负责故障转移
    迁移槽和数据
        槽迁移计划
        迁移数据
            1.对目标节点发送：cluster setslot {slot} importing {sourceNodeId}命令，让目标节点准备导入槽的数据
            2.对源节点发送：cluster setslot {slot} migrating {targetNodeID}命令，让源节点准备迁出槽的数据
            3.源节点循环执行cluster getKeysinslot {slot} {count}命令，每次获取count个属于槽的键
            4.在源节点上执行migrate {targetIp} {targetPort} key 0 {timeout} 命令指定key迁移
            5.重复执行步骤3~4直到槽下所有的键数据迁移到目标节点
            6.向集群内所有主节点发送cluster setslot {slot} node {targetNodeId}命令，通知槽分配给目标节点
        添加从节点
收缩集群
    下线迁移槽
    忘记节点
    关闭节点
客户端路由
    moved重定向
    ask重定向
    smart客户端(Jedis Cluster)
        1.从集群中选取一个可运行节点，只用cluster slots初始化槽和节点映射
        2.将cluster slots的结果映射到本地，为每个节点创建JedisPool
        3.准备执行命令
批量操作：
    方案      优点                            缺点                  网络IO
    串行mget  编程简单，少量keys满足需求          大量keys请求延迟严重    O(keys)
    串行IO    编程简单、少量节点满需求            大量node延迟严重        O(nodes)
    并行IO    利用并行特性，延迟取决于最慢的节点    编程复杂度高，超时定位难  O(max_slow(node))
    hash_tag 性能最高                         读写增加tag维护成本，tag分布易出现数据倾斜 O(1)
Redis Cluster的故障转移
    故障发现
        通过ping/pong消息实现故障发现：不需要sentinel
        主观下线：某个节点认为另一个节点不可用，"偏见"
        客观下线：当半数以上持有槽的主节点都标记某节点主观下线
    故障恢复
        资格检查
            每个从节点检查与故障主节点的断线时间
            超过cluster-node-timeout * cluster-slave-validity-factor取消资格
            cluster-slave-validity-factor:默认是10
        准备选举时间
        选举投票
        替换主节点
            当前从节点取消复制变为主节点（salveof no one）
            执行clusterDelSlot撤销故障主节点负责的槽，并执行clusterAddSlot把这些槽分配给自己
            向集群广播自己的pong消息，表明已经替换了故障从节点
    故障演练
Redis Cluster开发运维常见问题
    集群完整性
        cluster-require-full-coverage默认为yes
            集群中16384个槽全部可用：保证集群完整性
            节点故障或者正在故障转移：（error）CLUSTERDOWN The cluster is down
        大多数业务无法容忍，cluster-require-full-coverage建议设置为no
    带宽消耗
        官方建议：节点不要超过1000个
        ping/pong消息
        不容忽视的带宽消耗
            消息发送频率：节点发现与其他节点最后通信时间超过cluster-node-timeout/2时会直接发送ping消息
            消息数据量：slots槽数据（2KB空间）和整个集群1/10的状态数据（10个节点状态数据约为1KB）
            节点部署的机器规模：集群分布的机器越多且每台机器划分的节点数越均匀，则集群内整体的可用带宽越高
        优化：
            避免"大"集群：避免多业务使用一个集群，大业务可以多集群
            cluster-node-timeout：带宽和故障转移速度的均衡
            尽量分配到多机器上：保证高可用和带宽
    Pub/Sub广播
        问题：publish在集群每个节点广播：加重带宽
        解决：单独"走"一套Redis Sentinel
    集群倾斜
        数据倾斜：内存不均匀
            节点和槽分配不均匀
            不同槽对应键值数量差异较大
            包含bigkey
            内存相关配置不一致
        请求倾斜：热点
            热点key：重要的key或者bigkey
            优化：
                避免bigkey
                热键不要用hash_tag
                当一致性不高时，可以用本地缓存 + MQ
    读写分离
        只读连接：集群模式的从节点不接受任何读写请求
            重定向到负责槽的主节点
            readonly命令可以读：连接级别的命令
        读写分离：更加复杂
            同样的问题：复制延迟、读取过期数据、从节点故障
            修改客户端：cluster slave {nodeId}
            集群模式下不建议使用读写分离
    数据迁移
        官方迁移工具：redis-trib.rb import
            只能从单机迁移数据到集群
            不支持在线迁移：source需要停写
            不支持断点续传
            单线程迁移：影响速度
        在线迁移：
        唯品会：redis-migrate-tool工具
        豌豆荚：redis-port工具
    集群vs单机
        集群限制
            key批量操作支持有限：例如mget、mset必须在一个slot
            key事务和lua支持有限：操作的key必须在一个节点上
            key是数据分区的最小粒度：不支持bigkey分区
            不支持多个数据库：集群模式下只有db0
            复制只支持一层：不支持树形复制结构
        分布式Redis不一定好
            Redis Cluster：满足容量和性能的扩展性，很多业务"不需要"。
                大多数时客户端性能会"降低"
                命令无法跨节点使用：mget、keys、scan、flush、sinter等
                Lua和事务无法跨节点能使用
                客户端维护更复杂：SDK和应用本身消耗（例如更多的连接池）
            很多场景下Redis Sentinel已经足够好了
集群总结
    Redis Cluster数据分区规则采用虚拟槽方式（16384个槽），每个节点负责一部分槽和相关数据，实现数据和请求的负载均衡
    搭建集群划分为四个步骤：准备节点、节点握手、分配槽、复制。redis-trib.rb工具用于快速搭建集群
    集群伸缩通过在节点之间移动槽和相关数据实现
        扩容时根据槽迁移计划把槽从源节点迁移到新节点
        收缩时如果下线的节点有负责的槽需要迁移到其他节点，再通过cluster forget命令让集群内所有的节点忘记被下线的节点
    使用smart客户端操作集群达到通信效率最大化，客户端内部负责计算维护键->槽->节点的映射，用于快速定位到目标节点
    集群自动故障转移过程分为故障发现和节点恢复。节点下线分为主观下线和客观下线，当超过半数主节点认为故障节点为主观下线时表姐它为客观下线状态。从节点负责对客观下线的主节点触发故障恢复流程，保证集群的可用性
    开发运维常见问题包括：超大规模集群带宽消耗，pub/sub广播问题，集群倾斜问题，单机和集群对比等。

缓存的使用与设计
    缓存的收益与成本
        收益
            加速读写
            降低后端负载：后端服务器通过前端缓存降低负载：业务端使用Redis降低后端MySQL负载等
        成本
            数据不一致：缓存层和数据层有时间窗口不一致，和更新策略有关
            代码维护成本：多了一层缓存逻辑
            运维成本：例如Redis Cluster
        使用场景
            降低后端负载
                对高消耗的SQL：join结果集/分组统计结果缓存
            加速请求响应
                利用Redis/Memcache优化IO响应时间
            大量写合并为批量写
                如计数器先Redis累加再批量写DB
    缓存更新策略
        LRU/LFU/FIFO算法剔除：例如maxmemory-policy，一致性最差，维护成本低
        超时剔除：例如expire，一致性较差，维护成本低
        主动更新：开发控制生命周期，一致性强，维护成本高
        两条建议：
            低一致性：最大内存淘汰策略
            高一致性：超时剔除和主动更新结合，最大内存和淘汰策略兜底
    缓存粒度控制
        三个角度
            通用性：全量属性更好
            占用空间：部分属性更好
            代码维护：表面上全量属性更好
    缓存穿透优化（大量请求不命中）
        原因
            业务代码自身问题
            恶意攻击、爬虫等
        如何发现
            业务的响应时间
            业务本身问题
            相关指标：总调用数、缓存层命中数、存储层命中数
        解决方法
            缓存空对象
                两个问题
                    需要更多的键
                    缓存层和存储层数据"短期"不一致
            布隆过滤器拦截
    无底洞问题优化
        分布式缓存中，有更多的机器不保证有更高的性能
        有四种批量操作方式：串行命令、串行IO、并行IO、hash_tag
    缓存雪崩优化
        缓存层高可用、客户端降级、提前演练是解决雪崩问题的重要方法
    热点Key重建优化
        互斥锁、"永不过期"能够在一定程度上解决热点key问题，开发人员在使用时要了解它们各自的使用成本