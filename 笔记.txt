数据结构和内部编码
String：raw、int、embstr
hash：hashtable、ziplist（压缩列表）
list：linkedlist、ziplist
set：hashtable、intset
zset：skiplist、ziplist

单线程为什么这么快：
1.纯内存
2.非阻塞IO
3.避免线程切换和竞态消耗

字符串类型String
场景：缓存、计数器、分布式锁等等
set key value：不管key是否存在，都设置，O(1)
setnx key value：key不存在才设置，O(1)
set key value xx：key存在才设置，O(1)
mget key1 key2 key3...：批量获取key，原子操作，O(n)
mset key1 value1 key2 value2 key3 value3...：批量设置key-value，O(n)
getset key newvlaue：set key newvlaue并返回旧的value，O(1)
append key value：将value追加到旧value， O(1)
strlen key：返回字符串的长度（注意中文），O(1)

哈希类型Hash（small redis，类似于MapMap的结构，本身是一个map结构，其中的value也是一个map）
hget key filed：获取hash key对应的filed的value，O(1)
hset key field value：设置hash key对应的field的value，O(1)
hdel key field：删除hash key对应field的value，O(1)
hexists key field：判断hash key是否有field，O(1)
hlen key：获取hash key field的数量，O(1)
hmget，hmset类似于String的mset和mget
hgetall key：返回hash key对应所有的field和value，O(n)
hvals key：返回hash key对应所有field的value，O(n)
hkeys key：返回hash key对应所有的field，O(n)

list类型
rpush key value1 value2 ... valueN：从列表右端插入值（1~N）个，O(1~N)
lpush key value1 value2 ... valueN：从列表左端插入值（1~N）个，O(1~N)
linsert key before|after value newValue：在list指定的值之前|后插入newValue，O(n)
lpop key：从列表左端弹出一个value，O(1)
rpop key：从列表右侧弹出一个value，O(1)
lrem key count value：根据count值，从列表中删除所有的value相等的项，
                     count>0，从左到右，删除最多count个与value相等的值
                     count<0，从右到左，删除最多Math.abs（count）个与value相等的值
                     count=0，删除所有的与value相等的值
ltrim key start end：按照索引范围修剪列表
lrange key start end：获取列表指定索引范围所有的value（包括end），O(n)
lindex key index：获取列表指定索引的value，O(n)
llen key：获取列表长度，O(1)
lset key index newValue：设置列表指定索引值为newValue，O(n)
blpop/brpop key timeout：lpop阻塞版本，timeout是阻塞超时时间，timeout=0表示永不阻塞，O(1)
命令组合：1.lpush + lpop = stack
        2.lpush + rpop = queue
        3.lpush + ltrim = capped collection固定大小的容器
        4.lpush + brpop = message queue

集合set
sadd key element：向集合key添加element（如果element已存在，则添加失败），O(1)
scard key：统计集合元素个数
sismember key element：元素element是否在集合key中
srandmember key count：从集合key中随机取出count个元素，但该元素不会被从集合删除
spop key：从集合key中随机弹出一个元素，弹出后集合就不存在该元素
smembers key：取出集合key中的所有元素
srem key element：将集合key中的element移除掉，O(1)
sdiff key1 key2：输出集合key1和key2的差集（key1 - key2）
sinter key1 key2：输出集合key1和key2的交集
sunion key1 key2：输出key1和key2的并集
sdiff|sinter|sunion store destkey：将差|交|并集存在集合destkey中
命令组合实战：sadd = tagging做标签
           spop/srandmember = random item 随机操作，例如抽奖
           sadd + sinter = social graph社交网络，共同好友

有序集合zset
特点：key ： value（score ： value），无重复元素，有序，value由score + element组成，score保证顺序
zadd key score element（可以是多对）：添加score和element，O(logN)
zrem key element（可以是多个）：删除元素
zscore key element：返回元素的分数
zincreby key increScore element：增加或减少元素的score，O(1)
zcard key：返回元素的个数，O(1)
zrank|zrevrank key element：返回element在集合中的升序|降序顺序
zrange|zrevrange key start end [withscores]：返回指定索引范围内的升序|降序元素[分值]，O(logn + m）
zrangebyscore|zrevrangebyscore key minscore maxscore [withscores]：返回指定范围内的升序|降序元素[分值]
zcount key minscore maxscore：返回有序集合内指定范围内的元素个数，O(logn + m）
zremrangebyrank key start end：删除指定排名内的升序元素，O(logn + m）
zremrangebyscore key minscore maxscore：删除指分数内的升序元素，O(logn + m）
实战：排行榜

慢查询
客户端与redis服务器交互的生命周期：1.客户端发送命令 2.命令排队 3.执行命令 4.服务器返回给客户端结果
慢查询发生在第3阶段
客户端超时不一定是因为慢查询，但慢查询是客户端超时的一个可能因素
慢查询的两个配置
1.slowlog-max-len  先进先出队列，固定长度，保存在内存内
2.slowlog-log-slower-than  慢查询阈值（单位：微秒，0.001毫秒）
                           slowlog-log-slower-than = 0 记录所有命令
                           slowlog-log-slower-than < 0 不记录任何命令
慢查询命令：
1.slowlog get [n] ：获取慢查询队列
2.slowlog len：获取慢查询队列长度
运维经验：
1.slowlog-max-len不要设置过大，默认10ms，通常设置为1ms
2.slowlog-log-slower-than不要设置过小，通常在1000左右
3.理解生命周期

流水线pipeline（打包发送一批命令去服务端执行，节省网络传输时间）
1次pipeline（n条命令） = 1次网络时间 + n次命令时间
注意：1.redis的命令时间是微妙级别
     2.pipeline每次条数要控制（网络）
使用建议：
    1.注意每次pipeline携带的数据量
    2.pipeline每次只能作用在一个redis节点上

发布订阅
角色：发布者（publisher）、订阅者（subscriber）、频道（channel）
publish channel message ：发布消息，返回订阅者数量
subscribe [channel] ：订阅一个或多个频道
unsubscribe [channel] ：取消订阅一个或多个频道

位图bitmap
setbit key offset value ：给位图指定索引设置值
getbit key offset ：获取位图指定索引的值
bitcount key [start end] ：获取指定范围（start - end，单位为字节，如果不指定就是获取全部）位值为1的个数
bitop op destkey key [key...] ：做多个Bitmap的and（交集）、or（并集）、not（非）、xor（异或）操作，并将结果保存在destkey中
bitops key targetBit [start][end] ：计算位图指定范围（start到end，单位为字节，如果不指定就是获取全部）第一个偏移量对应的值等于targetBit的位置

HyperLoglog
基于HyperLoglog算法：极小空间完成独立数量统计
本质还是字符串
pfadd key element [element...] ：向hyperloglog添加元素
pfcount key [key...] ：计算hyperloglog的独立总数
pfmerge destkey sourcekey [sourcekey...] ：合并多个hyperloglog
使用经验：
    1.是否能容忍错误？错误率0.81%
    2.是否需要取出单挑数据？hyperloglog做不到

GEO
GEO(地理信息定位，Geographic information positioning)
存储经纬度，计算两地距离，范围计算等
geoadd key longitude latitude member [longitude latitude member...] ：增加地理位置信息
geopos key member [member...] ：获取地理位置信息
geodist key member1 member2 [unit] ：获取两个地理位置的距离，unit：m（米）、km（千米）、mi（英尺）、ft（尺）
相关说明：
    1.since3.2+
    2、数据类型是zset
    3.没有删除API，可用zset的删除操作进行删除：zrem key member

持久化RDB、AOF
redis所有数据保存在内存中，对数据的更新将异步地保存在磁盘上。
持久化方式：
    快照：1.MySQL Dump   2.Redis RDB
    写日志：1.MySQL Binlog   2.Hbase Hlog   3.Redis AOF

RDB
触发机制（三种）：save（同步）、bgsave（异步）、自动生成
save命令：文件策略：如存在老的RDB文件，新的替换老的，复杂度：O(n)
bgsave命令：异步创建子进程进行RDB操作，文件策略与save相同
自动生成RDB：在redis.conf文件中进行配置（内部是运行bgsave进行RDB的生成）
总结：1.RDB是Redis内存到硬盘的快照，用于持久化
     2.save命令通常会阻塞Redis
     3.bgsave不会阻塞Redis，但是会fork新进程
     4.save自动配置满足任意一个就会被执行（一般不使用自动策略）
     5.一些触发RDB的机制不容忽视（全量复制、debug reload、shutdown等）

AOF
RDB存在的问题：1.耗时、耗性能 2.不可控、丢失数据
AOF的三种策略：
    1.always：实时写入AOF文件，优点：不丢失数据   缺点：IO开销大，一般的SATA盘只有几百TPS
    2.everysec：每秒写一次AOF文件（配置默认值），优点：每秒一次fsync   缺点：丢失1s数据
    3.no：操作系统决定什么时候进行AOF操作，优点：不用管   缺点：不可控
AOF重写：1.AOF持久化是通过保存被执行的写命令来记录数据库状态的，所以AOF文件的大小随着时间的流逝一定会越来越大；
        影响包括但不限于：对于Redis服务器，计算机的存储压力；AOF还原出数据库状态的时间增加；
        2.为了解决AOF文件体积膨胀的问题，Redis提供了AOF重写功能：Redis服务器可以创建一个新的AOF文件来替代现有的AOF文件，
        新旧两个文件所保存的数据库状态是相同的，但是新的AOF文件不会包含任何浪费空间的冗余命令，
        通常体积会较旧AOF文件小很多。
AOF重写实现的两种方式：1.bgrewriteaof，fork子进程进行AOF重写
                   2.AOF重写配置，auto-aof-rewrite-min-size aof文件重写需要的尺寸
                                auto-aof-rewrite-percentage aof文件增长率

RDB个AOF的抉择
对比： 命令          RDB         AOF
      启动优先级     低          高（同时存在优先加载）
      体积          小          大
      恢复速度       快          慢
      数据安全性     丢数据       根据策略而定
      轻重          重          轻

Redis持久化在开发运维常见问题
fork操作：
    1.同步操作
    2.执行时间与内存量息息相关：内存越大，耗时越长（与机器类型有关）
    3.info：latest_fork_usec 上一次执行fork操作所耗微秒数，该数字如果较大会阻塞Redis
改善fork
    1.优先使用物理机或者高效支持fork操作的虚拟化技术
    2.控制Redis实例最大可用内存：maxmemory
    3.合理配置Linux内存分配策略：vm.overcommit_memory = 1
    4.降低fork频率：例如放宽AOF重写自动触发时机，不必要的全量复制
子进程开销和优化
    1.CPU：
        开销：RDB和AOF文件生成，属于CPU密集型
        优化：不做CPU绑定，不和CPU密集型一起部署
    2.内存：
        开销：fork内存开销，copy-on-write
        优化：系统方面可以进行优化
    3.硬盘
        开销：RDB和AOF文件写入，可以结合iostat，iotop分析
        优化：不要和高硬盘负载服务部署在一起：存储服务、消息队列等。
             no-appendfsync-on-rewrite = yes
             根据写入量决定磁盘类型：例如ssd
             单机多实例持久化文件目录可以考虑分盘

主从复制
一主一从、多主多从
主从复制的作用：数据副本、扩展读性能
总结：
    1.一个master可以有多个slave
    2.一个slave只能有一个master
    3.数据流是单向的，只能从master到slave
两种实现方式：1.slaveof命令      2.配置
全量复制开销：
    1.bgsave时间
    2.RDB文件网络传输时间
    3.从节点清空数据时间
    4.从节点加载RDB时间
    5.可能的AOF重写操作
部分复制：master保存一份缓冲buffer（类似于队列），slave重新连接的时候检测offset是否在队列中，
        若在，master会发送continue给slave，此时发生部分复制
        若不在，则会发生全量复制
故障处理：
    无故障转移
        slave宕机：将宕机掉的slave上的请求转移到其他的slave上
        master宕机：选取一个salve成为新的master对外提供服务
开发与运维中的问题：
    1.读写分离：读流量分摊到从节点
        可能遇到的问题：
            复制数据延迟
            读到过期的数据
            从节点故障
    2.配置不一致
        master和slave的maxmemory（slave的maxmemory小于master的maxmemory）不一致：丢失数据
        数据结构优化参数（例如hash-max-ziplist-entries）：内存不一致
    3.规避全量复制
        第一次全量复制
            出现情况：slave第一次去连接master，第一次不可避免
            解决方案：小主节点、低峰
        节点运行ID不匹配
            出现情况：主节点重启（运行ID变化）
            解决方案：故障转移，例如哨兵和集群
        复制积压缓冲区（默认1M）不足
            出现情况：网络中断，部分复制无法满足
            解决方案：增大缓冲区配置rel_backlog_size，网络增强
        避免复制风暴（master上挂载大量从节点，在master宕机后，会进行大量复制（生成rdb文件，大量传输））
            单主节点复制风暴
                出现情况：只有一个master节点，master节点重启，多从节点复制
                解决方案：更换复制拓扑
            单机器复制风暴
                出现情况：但台机器上放置多个master，机器宕机后，发生大量全量复制
                解决方案：主节点分散到多台机器上

Redis Sentinel
主从复制问题：1.手动故障转移 2.写能力和存储能力受限
三个定时任务
1.每10s每个sentinel对master和slave进行info
    发现slave节点
    确认主从关系
2.每2s每个sentinel通过master节点的channel交换信息（pub/sub）
    通过"_sentinel_:hello"频道交互
    交互对节点的"看法"和自身信息
3.每1s每个sentinel对其他sentinel和redis执行ping
    心跳检测，失败判定依据
主观下线和客观下线（判断是否下线master，即master是否有问题）
    主观下线：每个sentinel节点对redis节点失败的"偏见"
    客观下线：所有sentinel节点对redis节点失败"达成共识"（超过quorum统一）
            sentinel is-master-down-by-addr
领导者（sentinel）选举
    原因：只有一个sentinel节点完成故障转移
    选举：通过sentinel is-master-down-by-addr命令都希望成为领导者
        1.每个做主观下线的sentinel节点向其他sentinel节点发送的命令，要求将他设置为领导者
        2.收到命令的sentinel节点如果没有同意其他sentinel节点发送的命令，那么将同意该请求，否则拒绝
        3.如果该sentinel节点发现自己的票数已经超过sentinel集合半数且超过quorum，那么它将成为领导者
        4.如果此过程有多个sentinel节点成为了领导者，那么将等待一段时间重新进行选举
故障转移（sentinel领导者节点选举完成）
    1.从slave节点选出一个"合适的"节点作为新的master节点
    2.对上面的slave节点执行slaveof no one命令让其成为新的master节点
    3.向剩余的slave节点发送命令，让它们成为新的master节点的slave节点，复制规则和parallel-syncs参数有关
    4.更新原来的master节点配置为slave，并保持对其"关注"，当其恢复后命令它去复制新的master节点
选择"合适的"slave节点
    1.选择slave-priority（slave节点优先级）最高的节点，如果存在则返回，不存在则继续。
    2.选择复制偏移量最大的slave节点（复制的最完整），如果存在则返回，不存在则继续
    3.选择runId最小的slave节点
Redis Sentinel的常见开发运维问题
节点运维：主节点、从节点、sentinel节点
    1.机器下线：例如过保等情况
    2.机器性能不足：例如CPU、内存、硬盘、网络等
    3.节点自身故障：例如服务不稳定等
节点下线
    主节点下线:sentinel failover <mastername>手动下线主节点
    从节点：临时下线还是永久下线，例如是否做一些清理工作。但是要考虑读写分离的情况
    sentinel节点：同从节点
节点上线
    主节点：sentinel failover进行替换
    从节点：slaveof即可，sentinel节点可以感知
    sentinel节点：参考其他的sentinel节点启动即可
高可用读写分离（基于Redis Sentinel）
    从节点的作用：
        1.副本：高可用的基础
        2.扩展：读能力
    三个消息
        1.+switch-master：切换主节点（slave晋升为master）
        2.+convert-to-slave：切换从节点（原主节点降为从节点）
        3.+sdown：主观下线
总结：
    1.Redis Sentinel是Redis的高可用实现方案：故障发现、故障自动转移、配置中心、客户端通知
    2.Redis Sentinel从Redis2.8版本才开始正式生产可用，之前的版本生产不可用
    3.尽可能在不同的物理机器上部署Redis Sentinel所有节点
    4.Redis Sentinel的Sentinel节点个数应该大于等于3，且最好为奇数
    5.Redis Sentinel中的数据节点与普通数据节点没有区别
    6.客户端初始化时连接的是Sentinel节点集合，不再是具体的Redis节点，但是Sentinel只是配置中心，并不是代理
    7.Redis Sentinel通过三个定时任务实现了Sentinel节点对于主节点、从节点、其余Sentinel节点的监控
    8.Redis Sentinel在对节点做失败判定时分为主观下线和客观下线
    9.看懂Redis Sentinel故障转移日志对于Redis Sentinel以及问题排查非常有帮助
    10.Redis Sentinel实现读写分离高可用可以依赖Sentinel节点的消息通知，获取Redis节点数据的状态变化















